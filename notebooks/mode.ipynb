{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = \"../data/processed\"\n",
    "validation_csv = os.path.join(processed_data_path, \"validation_data.csv\")\n",
    "test_csv = os.path.join(processed_data_path, \"test_data.csv\")\n",
    "train_csv = os.path.join(processed_data_path, \"train_data.csv\")\n",
    "\n",
    "valid_df = pd.read_csv(validation_csv)\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    return Image.open(image_path)\n",
    "\n",
    "train_df['image_path'] = train_df['image']\n",
    "train_df['image'] = train_df['image_path'].apply(load_image)\n",
    "\n",
    "valid_df['image_path'] = valid_df['image']\n",
    "valid_df['image'] = valid_df['image_path'].apply(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"].unique()\n",
    "mapping = {\n",
    "    'Banana_Bad': 1,\n",
    "    'Lemon_Mixed': 2,\n",
    "    'Apple_Good' : 3, \n",
    "    'Guava_Mixed': 4,\n",
    "    'Guava_Bad' : 5, \n",
    "    'Lime_Bad':6, \n",
    "    'Pomegranate_Good':7,\n",
    "    'Guava_Good':8,\n",
    "    'Lime_Good':9, \n",
    "    'Banana_Good':10, \n",
    "    'Apple_Bad':11, \n",
    "    'Pomegranate_Bad':12,\n",
    "    'Orange_Good':13, \n",
    "    'Banana_Mixed':14, \n",
    "    'Orange_Bad':15, \n",
    "    'Pomegranate_Mixed':16,\n",
    "    'Orange_Mixed':17, \n",
    "    'Apple_Mixed':18\n",
    "}\n",
    "train_df['label'] = train_df['label'].map(mapping)\n",
    "valid_df['label'] = valid_df['label'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  image  label  \\\n",
      "0     <PIL.JpegImagePlugin.JpegImageFile image mode=...      1   \n",
      "1     <PIL.JpegImagePlugin.JpegImageFile image mode=...     13   \n",
      "2     <PIL.JpegImagePlugin.JpegImageFile image mode=...      8   \n",
      "3     <PIL.JpegImagePlugin.JpegImageFile image mode=...     10   \n",
      "4     <PIL.JpegImagePlugin.JpegImageFile image mode=...     17   \n",
      "...                                                 ...    ...   \n",
      "1948  <PIL.JpegImagePlugin.JpegImageFile image mode=...     15   \n",
      "1949  <PIL.JpegImagePlugin.JpegImageFile image mode=...     14   \n",
      "1950  <PIL.JpegImagePlugin.JpegImageFile image mode=...      7   \n",
      "1951  <PIL.JpegImagePlugin.JpegImageFile image mode=...      9   \n",
      "1952  <PIL.JpegImagePlugin.JpegImageFile image mode=...      7   \n",
      "\n",
      "                                             image_path  \n",
      "0     ../data/external/fruit_images/bad_quality_frui...  \n",
      "1     ../data/external/fruit_images/good_quality_fru...  \n",
      "2     ../data/external/fruit_images/good_quality_fru...  \n",
      "3     ../data/external/fruit_images/good_quality_fru...  \n",
      "4     ../data/external/fruit_images/mixed_quality_fr...  \n",
      "...                                                 ...  \n",
      "1948  ../data/external/fruit_images/bad_quality_frui...  \n",
      "1949  ../data/external/fruit_images/mixed_quality_fr...  \n",
      "1950  ../data/external/fruit_images/good_quality_fru...  \n",
      "1951  ../data/external/fruit_images/good_quality_fru...  \n",
      "1952  ../data/external/fruit_images/good_quality_fru...  \n",
      "\n",
      "[1953 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28490>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E284F0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E289D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28A90>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28B50>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28C70>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28D30>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28D90>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E28E50>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E55070>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E55190>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E55310>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E553D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E55730>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E557F0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E55910>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E811F0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E813D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E816D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E81730>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E817F0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E81AF0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E81D30>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3E81FD0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAE250>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAE310>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAE370>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAE670>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAEC10>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAED90>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EAEFD0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC0D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC2B0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC3D0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC610>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC7F0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC910>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDC970>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDCCD0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDCD90>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=224x224 at 0x1D7E3EDCEB0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E68D93A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E68D9940>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E68D9E20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69069A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6906B20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6906BE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6937160>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6937220>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E69378E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6937D00>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6964880>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6964DC0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69971C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69978E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6997EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69C4E20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E69F6580>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E69F67C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69F69A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69F6E80>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E69F6EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A24100>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A241C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6A53280>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E6A536A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A53940>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A53EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A81400>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6A81640>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AB01C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AB02E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6AB0760>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AB0AC0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AB0D60>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AB0F40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AE0100>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AE0160>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AE02E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6AE0B20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B0F160>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B0F520>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B0F7C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B0FC40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B3BA00>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B3BB80>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B3BE80>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B6D940>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B6DB20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B6DFA0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B9A400>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6B9A9A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6B9AC40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BCA220>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BCAD60>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BFF400>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BFF520>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BFFCA0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6BFFF40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6C2C340>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6C2C4C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6C2C580>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E6C2C5E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E6C2C700>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C2C2E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C2C6A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7C2CF40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C5D580>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E7C5D760>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C5D9A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C5DBE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C8B580>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7C8B6A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CBB1C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CBB280>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CBB5E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7CBBE20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CBBFD0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CEA2E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CEA520>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7CEA5E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7D19E80>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7D78B20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7D78EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7DA9100>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E7DA9460>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E7DA99A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7DA9F40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7DD70A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7DD7280>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7DD7CA0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E08400>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E08460>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E088E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E08A00>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E35580>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E35880>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E66B80>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E66EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E95460>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7E95640>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7E957C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7EF3940>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7EF3B20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7EF3EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7F541C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E7F545E0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7F54760>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=3000x4000 at 0x1D7E7F54940>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7F54EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7F83460>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7F83D00>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FB2100>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=8000x6000 at 0x1D7E7FB2460>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FB2DC0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FB2E20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FB2EE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FE27C0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FE2A60>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E7FE2BE0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80136A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E8013700>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80139A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E8013AC0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E8041C40>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E8070E20>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80A0640>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80A0FD0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80CF9A0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80CFCA0>\n",
      " RGB image <PIL.JpegImagePlugin.JpegImageFile image mode=L size=256x256 at 0x1D7E80CFFA0>\n"
     ]
    }
   ],
   "source": [
    "def check_and_transform_image(image):\n",
    "    if image.mode == \"L\":\n",
    "        # If it's a black and white image, convert it to RGB\n",
    "        print(f\" RGB image {image}\")\n",
    "        image = image.convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# Apply the function to each image path in the DataFrame\n",
    "train_df[\"image\"] = train_df[\"image\"].apply(check_and_transform_image)\n",
    "valid_df[\"image\"] = valid_df[\"image\"].apply(check_and_transform_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\30694\\Desktop\\DTU\\Year2\\MLOps\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "processor = ViTImageProcessor.from_pretrained(model_name_or_path)\n",
    "print(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_extractor):\n",
    "        self.dataframe = dataframe\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataframe.iloc[idx, 0]  # Assuming the \"image\" column contains actual images\n",
    "        label = self.dataframe.iloc[idx, 1]  # Assuming the \"label\" column is at index 1 \n",
    "        \n",
    "        pixel_values = self.feature_extractor(image, return_tensors=\"pt\").pixel_values\n",
    "        print(f\"image_path : {self.dataframe.iloc[idx, 2]}, shape: {pixel_values.shape}\")\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": torch.tensor(label)}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(dataframe=train_df, feature_extractor=processor)\n",
    "val_dataset = CustomImageDataset(dataframe=valid_df, feature_extractor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path : ../data/external/fruit_images/bad_quality_fruits\\Banana_Bad\\IMG_20190910_175634.jpg, shape: torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[0.5686, 0.5765, 0.5922,  ..., 0.8275, 0.8275, 0.8667],\n",
       "           [0.6078, 0.5922, 0.5843,  ..., 0.8431, 0.8353, 0.8588],\n",
       "           [0.5608, 0.5373, 0.5294,  ..., 0.8745, 0.8510, 0.8588],\n",
       "           ...,\n",
       "           [0.4431, 0.4275, 0.3961,  ..., 0.9608, 0.9686, 0.9686],\n",
       "           [0.4039, 0.3804, 0.3569,  ..., 0.9843, 0.9765, 0.9686],\n",
       "           [0.4510, 0.4196, 0.3725,  ..., 1.0000, 0.9765, 0.9529]],\n",
       " \n",
       "          [[0.5843, 0.5922, 0.6078,  ..., 0.8431, 0.8431, 0.8824],\n",
       "           [0.6235, 0.6078, 0.6000,  ..., 0.8588, 0.8510, 0.8745],\n",
       "           [0.5765, 0.5529, 0.5451,  ..., 0.8902, 0.8667, 0.8745],\n",
       "           ...,\n",
       "           [0.4588, 0.4431, 0.4118,  ..., 0.9686, 0.9765, 0.9765],\n",
       "           [0.4196, 0.3961, 0.3725,  ..., 0.9922, 0.9843, 0.9765],\n",
       "           [0.4667, 0.4353, 0.3882,  ..., 1.0000, 0.9843, 0.9608]],\n",
       " \n",
       "          [[0.5608, 0.5686, 0.5843,  ..., 0.8196, 0.8196, 0.8588],\n",
       "           [0.6000, 0.5843, 0.5765,  ..., 0.8353, 0.8275, 0.8510],\n",
       "           [0.5529, 0.5294, 0.5216,  ..., 0.8667, 0.8431, 0.8510],\n",
       "           ...,\n",
       "           [0.4510, 0.4353, 0.4039,  ..., 0.9294, 0.9373, 0.9373],\n",
       "           [0.4118, 0.3882, 0.3647,  ..., 0.9529, 0.9451, 0.9373],\n",
       "           [0.4588, 0.4275, 0.3804,  ..., 0.9686, 0.9451, 0.9216]]]]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path : ../data/external/fruit_images/good_quality_fruits\\Guava_Good\\IMG_8625.JPG, shape: torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[ 0.3725,  0.3725,  0.4353,  ...,  0.7412,  0.8196,  0.6314],\n",
       "           [ 0.3647,  0.4902,  0.4667,  ...,  0.7333,  0.7490,  0.6863],\n",
       "           [ 0.4196,  0.4980,  0.5137,  ...,  0.7333,  0.5137,  0.5843],\n",
       "           ...,\n",
       "           [-0.3098, -0.3020, -0.2706,  ..., -0.1451, -0.0353,  0.0118],\n",
       "           [-0.2549, -0.3333, -0.3725,  ..., -0.1216, -0.0745,  0.0039],\n",
       "           [-0.3569, -0.2863, -0.1686,  ..., -0.1059,  0.1216,  0.0980]],\n",
       " \n",
       "          [[ 0.3647,  0.3647,  0.4275,  ...,  0.7098,  0.7882,  0.6000],\n",
       "           [ 0.3569,  0.4824,  0.4588,  ...,  0.7020,  0.7176,  0.6549],\n",
       "           [ 0.4118,  0.4902,  0.5059,  ...,  0.7020,  0.4824,  0.5529],\n",
       "           ...,\n",
       "           [-0.3255, -0.3176, -0.2863,  ..., -0.1922, -0.0824, -0.0353],\n",
       "           [-0.2706, -0.3490, -0.3882,  ..., -0.1686, -0.1216, -0.0431],\n",
       "           [-0.3725, -0.3020, -0.1843,  ..., -0.1529,  0.0745,  0.0431]],\n",
       " \n",
       "          [[ 0.4275,  0.4275,  0.4902,  ...,  0.7176,  0.7961,  0.6078],\n",
       "           [ 0.4196,  0.5451,  0.5216,  ...,  0.7098,  0.7255,  0.6627],\n",
       "           [ 0.4745,  0.5529,  0.5686,  ...,  0.7098,  0.4902,  0.5608],\n",
       "           ...,\n",
       "           [-0.2235, -0.2157, -0.1843,  ..., -0.0824,  0.0275,  0.0745],\n",
       "           [-0.1686, -0.2471, -0.2863,  ..., -0.0588, -0.0039,  0.0745],\n",
       "           [-0.2706, -0.2000, -0.0824,  ..., -0.0431,  0.1922,  0.1686]]]]),\n",
       " 'labels': tensor(8)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "valid_dataloader = DataLoader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "labels = train_df['label'].unique().tolist()\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import softmax\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoFeatureExtractor, get_scheduler\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "valid_dataloader = DataLoader(val_dataset)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "epochs = 3\n",
    "\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=\"Batch\", leave=False):\n",
    "\n",
    "        batch[\"pixel_values\"] = torch.squeeze(batch[\"pixel_values\"], 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        y_pred = model(**batch)\n",
    "\n",
    "        class_pred = torch.argmax(softmax(y_pred.logits, dim=1), dim=1)\n",
    "\n",
    "        is_correct = (\n",
    "            class_pred.detach().cpu().numpy() == np.array(batch[\"labels\"].cpu())\n",
    "        ).sum()\n",
    "\n",
    "        accuracy += is_correct\n",
    "\n",
    "        loss = y_pred.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    running_loss /= len(train_dataloader)\n",
    "    accuracy /= len(train_dataloader)\n",
    "\n",
    "    print(f\"Training Loss: {running_loss}, Training Accuracy: {accuracy}\")\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader, desc=\"Validation\", leave=False):\n",
    "            batch[\"pixel_values\"] = torch.squeeze(batch[\"pixel_values\"], 1)\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            y_pred = model(**batch)\n",
    "\n",
    "            class_pred = torch.argmax(softmax(y_pred.logits, dim=1), dim=1)\n",
    "\n",
    "            is_correct = (\n",
    "                class_pred.detach().cpu().numpy() == np.array(batch[\"labels\"].cpu())\n",
    "            ).sum()\n",
    "\n",
    "            accuracy += is_correct\n",
    "\n",
    "            loss = y_pred.loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(valid_dataloader)\n",
    "        accuracy /= len(valid_dataloader)\n",
    "\n",
    "        print(f\"Validation Loss: {running_loss}, Validation Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
